{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "part3.py\n",
    "\n",
    "UNSW COMP9444 Neural Networks and Deep Learning\n",
    "\n",
    "ONLY COMPLETE METHODS AND CLASSES MARKED \"TODO\".\n",
    "\n",
    "DO NOT MODIFY IMPORTS. DO NOT ADD EXTRA FUNCTIONS.\n",
    "DO NOT MODIFY EXISTING FUNCTION SIGNATURES.\n",
    "DO NOT IMPORT ADDITIONAL LIBRARIES.\n",
    "DOING SO MAY CAUSE YOUR CODE TO FAIL AUTOMATED TESTING.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    \"\"\"\n",
    "    DO NOT MODIFY\n",
    "    Linear (10) -> ReLU -> LogSoftmax\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # make sure inputs are flattened\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(x, dim=1)  # preserve batch dim\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO: Implement the following network structure\n",
    "    Linear (256) -> ReLU -> Linear(64) -> ReLU -> Linear(10) -> ReLU-> LogSoftmax\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO: Implement CNN Network structure\n",
    "\n",
    "    conv1 (channels = 10, kernel size= 5, stride = 1) -> Relu -> max pool (kernel size = 2x2) ->\n",
    "    conv2 (channels = 50, kernel size= 5, stride = 1) -> Relu -> max pool (kernel size = 2x2) ->\n",
    "    Linear (256) -> Relu -> Linear (10) -> LogSoftmax\n",
    "\n",
    "\n",
    "    Hint: You will need to reshape outputs from the last conv layer prior to feeding them into\n",
    "    the linear layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv2 = nn.Conv2d(10, 50, 5, stride=1)\n",
    "        \n",
    "        #linear layer\n",
    "        self.fc1 = nn.Linear(50 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class NNModel:\n",
    "    def __init__(self, network, learning_rate):\n",
    "        \"\"\"\n",
    "        Load Data, initialize a given network structure and set learning rate\n",
    "        DO NOT MODIFY\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a transform to normalize the data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Download and load the training data\n",
    "        trainset = datasets.KMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # Download and load the test data\n",
    "        testset = datasets.KMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "        self.model = network\n",
    "\n",
    "        \"\"\"\n",
    "        TODO: Set appropriate loss function such that learning is equivalent to minimizing the\n",
    "        cross entropy loss. Note that we are outputting log-softmax values from our networks,\n",
    "        not raw softmax values, so just using torch.nn.CrossEntropyLoss is incorrect.\n",
    "        \n",
    "        Hint: All networks output log-softmax values (i.e. log probabilities or.. likelihoods.). \n",
    "        \"\"\"\n",
    "        self.lossfn = torch.nn.NLLLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        self.num_train_samples = len(self.trainloader)\n",
    "        self.num_test_samples = len(self.testloader)\n",
    "\n",
    "    def view_batch(self):\n",
    "        \"\"\"\n",
    "        TODO: Display first batch of images from trainloader in 8x8 grid\n",
    "\n",
    "        Do not make calls to plt.imshow() here\n",
    "\n",
    "        Return:\n",
    "           1) A float32 numpy array (of dim [28*8, 28*8]), containing a tiling of the batch images,\n",
    "           place the first 8 images on the first row, the second 8 on the second row, and so on\n",
    "\n",
    "           2) An int 8x8 numpy array of labels corresponding to this tiling\n",
    "        \"\"\"\n",
    "        from torchvision import utils\n",
    "        for i_batch, sample_batched in enumerate(self.trainloader):\n",
    "            images_batch, landmarks_batch = \\\n",
    "                    sample_batched[0], sample_batched[1]\n",
    "\n",
    "            grid = utils.make_grid(images_batch)\n",
    "            grid = grid.numpy().transpose((1,2,0)).astype(np.float32)\n",
    "            \n",
    "            assert grid.dtype == np.float32\n",
    "            \n",
    "            return grid, landmarks_batch.numpy().reshape((8,8))\n",
    "\n",
    "    def train_step(self):\n",
    "        \"\"\"\n",
    "        Used for submission tests and may be usefull for debugging\n",
    "        DO NOT MODIFY\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        for images, labels in self.trainloader:\n",
    "            log_ps = self.model(images)\n",
    "            loss = self.lossfn(log_ps, labels)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        for images, labels in self.trainloader:\n",
    "            log_ps = self.model(images)\n",
    "            loss = self.lossfn(log_ps, labels)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.testloader:\n",
    "                log_ps = self.model(images)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        return accuracy / self.num_test_samples\n",
    "\n",
    "\n",
    "def plot_result(results, names):\n",
    "    \"\"\"\n",
    "    Take a 2D list/array, where row is accuracy at each epoch of training for given model, and\n",
    "    names of each model, and display training curves\n",
    "    \"\"\"\n",
    "    for i, r in enumerate(results):\n",
    "        plt.plot(range(len(r)), r, label=names[i])\n",
    "    plt.legend()\n",
    "    plt.title(\"KMNIST\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Test accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"./part_2_plot.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    models = [Linear(), FeedForward(), CNN()]  # Change during development\n",
    "#     models = [CNN()]  # Change during development\n",
    "    epochs = 10\n",
    "    results = []\n",
    "\n",
    "    # Can comment the below out during development\n",
    "#     images, labels = NNModel(Linear(), 0.003).view_batch()\n",
    "#     print(labels)\n",
    "#     plt.imshow(images, cmap=\"Greys\")\n",
    "#     plt.show()\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"Training {model.__class__.__name__}...\")\n",
    "        m = NNModel(model, 0.003)\n",
    "\n",
    "        accuracies = [0]\n",
    "        for e in range(epochs):\n",
    "            m.train_epoch()\n",
    "            accuracy = m.eval()\n",
    "            print(f\"Epoch: {e}/{epochs}.. Test Accuracy: {accuracy}\")\n",
    "            accuracies.append(accuracy)\n",
    "        results.append(accuracies)\n",
    "\n",
    "    plot_result(results, [m.__class__.__name__ for m in models])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear...\n",
      "Epoch: 0/10.. Test Accuracy: 0.49542197585105896\n",
      "Epoch: 1/10.. Test Accuracy: 0.4929339289665222\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
